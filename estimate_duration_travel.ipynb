{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Objective of the challenge: </h1>\n",
    "<p> we aim to build a model that predict the estimated duration of the travel. <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data cleaning and preparation\n",
    "This dataset coming from mobility startup that lets any user to book a ride to from any point A to any point B  within the city using a smartphone. Ride value is calculated at the time of request automatically  by the app, considering distance, estimated travel time, and current car availability (demand /  offer balance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " #import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journey_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>icon</th>\n",
       "      <th>start_type</th>\n",
       "      <th>start_at</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lon</th>\n",
       "      <th>end_at</th>\n",
       "      <th>...</th>\n",
       "      <th>price_distance</th>\n",
       "      <th>price_duration</th>\n",
       "      <th>distance</th>\n",
       "      <th>duration</th>\n",
       "      <th>cost</th>\n",
       "      <th>cost_distance</th>\n",
       "      <th>cost_duration</th>\n",
       "      <th>source</th>\n",
       "      <th>driver_score</th>\n",
       "      <th>rider_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23a1406fc6a11d866e3c82f22eed4d4c</td>\n",
       "      <td>0e9af5bbf1edfe591b54ecdfd7e91e26</td>\n",
       "      <td>583949a89a9ee17d19e3ca4f137b6b4c</td>\n",
       "      <td>b12f4f09c783e29fe0d0ea624530db56</td>\n",
       "      <td>executive</td>\n",
       "      <td>asap</td>\n",
       "      <td>16/11/2010 16:44</td>\n",
       "      <td>-12,13983536</td>\n",
       "      <td>-77,02355957</td>\n",
       "      <td>16/11/2010 17:29</td>\n",
       "      <td>...</td>\n",
       "      <td>3626.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>11331.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd2af4715d0dc16eded53afc0e243577</td>\n",
       "      <td>a553c46e3a22fb9c326aeb3d72b3334e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>executive</td>\n",
       "      <td>asap</td>\n",
       "      <td>01/06/2010 0:34</td>\n",
       "      <td>-12,13874817</td>\n",
       "      <td>-76,99536133</td>\n",
       "      <td>01/06/2010 0:37</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dd91e131888064bf7df3ce08f3d4b4ad</td>\n",
       "      <td>a553c46e3a22fb9c326aeb3d72b3334e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>executive</td>\n",
       "      <td>asap</td>\n",
       "      <td>31/05/2010 5:01</td>\n",
       "      <td>-12,12453079</td>\n",
       "      <td>-77,02780151</td>\n",
       "      <td>31/05/2010 5:04</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd2af4715d0dc16eded53afc0e2466d0</td>\n",
       "      <td>a553c46e3a22fb9c326aeb3d72b3334e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>executive</td>\n",
       "      <td>asap</td>\n",
       "      <td>01/06/2010 0:29</td>\n",
       "      <td>-12,13885117</td>\n",
       "      <td>-76,99530029</td>\n",
       "      <td>01/06/2010 0:32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85b7eabcf5d84e42dc7629b7d27781af</td>\n",
       "      <td>56772d544fdfa589a020a1ff894a86f7</td>\n",
       "      <td>d665fb9f75ef5d9cd0fd89479380ba78</td>\n",
       "      <td>0accdd3aa5a322f4129fa20b53278c69</td>\n",
       "      <td>executive</td>\n",
       "      <td>reserved</td>\n",
       "      <td>11/09/2010 23:55</td>\n",
       "      <td>-12,08995438</td>\n",
       "      <td>-76,92626953</td>\n",
       "      <td>12/09/2010 1:07</td>\n",
       "      <td>...</td>\n",
       "      <td>7665.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>30270.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>6173.0</td>\n",
       "      <td>5756.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         journey_id                           user_id  \\\n",
       "0  23a1406fc6a11d866e3c82f22eed4d4c  0e9af5bbf1edfe591b54ecdfd7e91e26   \n",
       "1  dd2af4715d0dc16eded53afc0e243577  a553c46e3a22fb9c326aeb3d72b3334e   \n",
       "2  dd91e131888064bf7df3ce08f3d4b4ad  a553c46e3a22fb9c326aeb3d72b3334e   \n",
       "3  dd2af4715d0dc16eded53afc0e2466d0  a553c46e3a22fb9c326aeb3d72b3334e   \n",
       "4  85b7eabcf5d84e42dc7629b7d27781af  56772d544fdfa589a020a1ff894a86f7   \n",
       "\n",
       "                          driver_id                           taxi_id  \\\n",
       "0  583949a89a9ee17d19e3ca4f137b6b4c  b12f4f09c783e29fe0d0ea624530db56   \n",
       "1                               NaN                               NaN   \n",
       "2                               NaN                               NaN   \n",
       "3                               NaN                               NaN   \n",
       "4  d665fb9f75ef5d9cd0fd89479380ba78  0accdd3aa5a322f4129fa20b53278c69   \n",
       "\n",
       "        icon start_type          start_at     start_lat     start_lon  \\\n",
       "0  executive       asap  16/11/2010 16:44  -12,13983536  -77,02355957   \n",
       "1  executive       asap   01/06/2010 0:34  -12,13874817  -76,99536133   \n",
       "2  executive       asap   31/05/2010 5:01  -12,12453079  -77,02780151   \n",
       "3  executive       asap   01/06/2010 0:29  -12,13885117  -76,99530029   \n",
       "4  executive   reserved  11/09/2010 23:55  -12,08995438  -76,92626953   \n",
       "\n",
       "             end_at  ... price_distance price_duration distance duration  \\\n",
       "0  16/11/2010 17:29  ...         3626.0          195.0  11331.0    234.0   \n",
       "1   01/06/2010 0:37  ...            NaN            NaN      0.0      0.0   \n",
       "2   31/05/2010 5:04  ...            NaN            NaN      0.0      0.0   \n",
       "3   01/06/2010 0:32  ...            NaN            NaN      0.0      0.0   \n",
       "4   12/09/2010 1:07  ...         7665.0          562.0  30270.0    715.0   \n",
       "\n",
       "     cost cost_distance cost_duration  source  driver_score  rider_score  \n",
       "0     0.0           0.0           0.0  iPhone           5.0          5.0  \n",
       "1     0.0           NaN           NaN  iPhone           NaN          NaN  \n",
       "2     0.0           NaN           NaN  iPhone           NaN          NaN  \n",
       "3     0.0           NaN           NaN  iPhone           NaN          NaN  \n",
       "4  6173.0        5756.0         417.0  iPhone           4.0          5.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading_data\n",
    "data=pd.read_csv(\"uber_peru_2010.csv\",sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rows and columns\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23111 entries, 0 to 23110\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   journey_id        23111 non-null  object \n",
      " 1   user_id           23111 non-null  object \n",
      " 2   driver_id         19726 non-null  object \n",
      " 3   taxi_id           19726 non-null  object \n",
      " 4   icon              23111 non-null  object \n",
      " 5   start_type        23111 non-null  object \n",
      " 6   start_at          23111 non-null  object \n",
      " 7   start_lat         23111 non-null  object \n",
      " 8   start_lon         23111 non-null  object \n",
      " 9   end_at            22835 non-null  object \n",
      " 10  end_lat           23111 non-null  object \n",
      " 11  end_lon           23111 non-null  object \n",
      " 12  end_state         23099 non-null  object \n",
      " 13  driver_start_lat  19621 non-null  object \n",
      " 14  driver_start_lon  19621 non-null  object \n",
      " 15  arrived_at        17716 non-null  object \n",
      " 16  currency          23111 non-null  object \n",
      " 17  price             22713 non-null  float64\n",
      " 18  price_distance    19941 non-null  float64\n",
      " 19  price_duration    19941 non-null  float64\n",
      " 20  distance          22848 non-null  float64\n",
      " 21  duration          22848 non-null  float64\n",
      " 22  cost              21760 non-null  float64\n",
      " 23  cost_distance     18038 non-null  float64\n",
      " 24  cost_duration     18038 non-null  float64\n",
      " 25  source            22988 non-null  object \n",
      " 26  driver_score      7650 non-null   float64\n",
      " 27  rider_score       15390 non-null  float64\n",
      "dtypes: float64(10), object(18)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_distance</th>\n",
       "      <th>price_duration</th>\n",
       "      <th>distance</th>\n",
       "      <th>duration</th>\n",
       "      <th>cost</th>\n",
       "      <th>cost_distance</th>\n",
       "      <th>cost_duration</th>\n",
       "      <th>driver_score</th>\n",
       "      <th>rider_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22713.000000</td>\n",
       "      <td>1.994100e+04</td>\n",
       "      <td>19941.000000</td>\n",
       "      <td>2.284800e+04</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>21760.000000</td>\n",
       "      <td>1.803800e+04</td>\n",
       "      <td>18038.000000</td>\n",
       "      <td>7650.000000</td>\n",
       "      <td>15390.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2752.738784</td>\n",
       "      <td>3.404748e+03</td>\n",
       "      <td>606.005617</td>\n",
       "      <td>1.088395e+04</td>\n",
       "      <td>638.831145</td>\n",
       "      <td>2655.032445</td>\n",
       "      <td>2.099408e+03</td>\n",
       "      <td>401.550504</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>4.755491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3025.390309</td>\n",
       "      <td>4.851010e+04</td>\n",
       "      <td>1553.548938</td>\n",
       "      <td>2.025735e+05</td>\n",
       "      <td>1788.661444</td>\n",
       "      <td>17124.801935</td>\n",
       "      <td>3.300314e+04</td>\n",
       "      <td>1148.614398</td>\n",
       "      <td>1.744948</td>\n",
       "      <td>0.840558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1700.000000</td>\n",
       "      <td>8.270000e+02</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1911.000000</td>\n",
       "      <td>1.754000e+03</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>4.660000e+03</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>1450.000000</td>\n",
       "      <td>1.048000e+03</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3597.000000</td>\n",
       "      <td>3.256000e+03</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>9.290250e+03</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>2381.250000</td>\n",
       "      <td>2.230000e+03</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>55974.000000</td>\n",
       "      <td>4.491910e+06</td>\n",
       "      <td>69839.000000</td>\n",
       "      <td>1.403722e+07</td>\n",
       "      <td>83807.000000</td>\n",
       "      <td>525000.000000</td>\n",
       "      <td>3.368792e+06</td>\n",
       "      <td>48887.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price  price_distance  price_duration      distance  \\\n",
       "count  22713.000000    1.994100e+04    19941.000000  2.284800e+04   \n",
       "mean    2752.738784    3.404748e+03      606.005617  1.088395e+04   \n",
       "std     3025.390309    4.851010e+04     1553.548938  2.025735e+05   \n",
       "min        0.000000    0.000000e+00        0.000000  0.000000e+00   \n",
       "25%     1700.000000    8.270000e+02       30.000000  0.000000e+00   \n",
       "50%     1911.000000    1.754000e+03      247.000000  4.660000e+03   \n",
       "75%     3597.000000    3.256000e+03      628.000000  9.290250e+03   \n",
       "max    55974.000000    4.491910e+06    69839.000000  1.403722e+07   \n",
       "\n",
       "           duration           cost  cost_distance  cost_duration  \\\n",
       "count  22848.000000   21760.000000   1.803800e+04   18038.000000   \n",
       "mean     638.831145    2655.032445   2.099408e+03     401.550504   \n",
       "std     1788.661444   17124.801935   3.300314e+04    1148.614398   \n",
       "min        0.000000       0.000000   0.000000e+00       0.000000   \n",
       "25%        0.000000       0.000000   0.000000e+00       0.000000   \n",
       "50%      218.000000    1450.000000   1.048000e+03     127.000000   \n",
       "75%      667.000000    2381.250000   2.230000e+03     414.000000   \n",
       "max    83807.000000  525000.000000   3.368792e+06   48887.000000   \n",
       "\n",
       "       driver_score   rider_score  \n",
       "count   7650.000000  15390.000000  \n",
       "mean       3.933333      4.755491  \n",
       "std        1.744948      0.840558  \n",
       "min        0.000000      0.000000  \n",
       "25%        4.000000      5.000000  \n",
       "50%        5.000000      5.000000  \n",
       "75%        5.000000      5.000000  \n",
       "max        5.000000      5.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and Trait missing values\n",
    "Feature Selection is one of the core concepts in machine learning which hugely impacts the performance of your model. The data features that you use to train your machine learning models have a huge influence on the performance you can achieve.  \n",
    "<b> Irrelevant or partially relevant features can negatively impact model performance. </b>\n",
    "\n",
    "Missing values are one of the most common problems you can encounter when you try to prepare your data for machine learning. The reason for the missing values might be human errors, interruptions in the data flow, privacy concerns, and so on. Whatever is the reason, missing values affect the performance of the machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for col in data.columns :\n",
    "    if (data[col].isnull().sum()!=0):\n",
    "        l.append([col,data[col].isnull().sum(),\"{:.0%}\".format(data[col].isnull().sum()/23111)])\n",
    "l.sort(key= lambda x:x[1],reverse=True)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_features =  ['icon','start_type','start_at', 'start_lat', 'start_lon', 'end_at', 'end_lat', 'end_lon',\n",
    "                    'end_state','source','distance' ,'cost_duration','price_duration','duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=data[chosen_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the distribution of the price_duration and cost_duration column to see if it's skewed or symmetrical. This will help us determine what value to replace the NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = features.copy()\n",
    "copy.dropna(inplace = True)\n",
    "sns.distplot(copy[\"price_duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"price_duration\"].fillna(features[\"price_duration\"].mean())\n",
    "features[\"cost_duration\"].fillna(features[\"cost_duration\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=features.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop(features[features['distance']==0].index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop(features[features['duration']==0].index , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 4 new variables, dayofweek number and name, month of day and hour of day.\n",
    "features['start_at'] = pd.to_datetime(features['start_at'], format=\"%d/%m/%Y %H:%M\")\n",
    "features['end_at'] = pd.to_datetime(features['end_at'], format=\"%d/%m/%Y %H:%M\")\n",
    "features['Month'] = features['start_at'].dt.month\n",
    "features['Hour'] = features['start_at'].dt.hour\n",
    "features['Day'] = features['start_at'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['time']=(features['end_at'] - features['start_at']).astype('timedelta64[m]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['DayOfWeekNum'] = features['start_at'].dt.dayofweek\n",
    "week=[\"lundi\",\"mardi\",\"mercredi\",\"jeudi\",\"vendredi\",\"samedi\",\"dimanche\"]\n",
    "def transfer(i):\n",
    "    return week[i]\n",
    "    \n",
    "features['DayOfWeek']=features['DayOfWeekNum'].apply(transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop([\"start_at\",\"end_at\"], axis = 1, inplace = True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lat(lat):\n",
    "    lat=lat.replace(',','.')\n",
    "    return float(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['end_lat']=features['end_lat'].apply(convert_lat)\n",
    "features['end_lon']=features['end_lon'].apply(convert_lat)\n",
    "features['start_lat']=features['start_lat'].apply(convert_lat)\n",
    "features['start_lon']=features['start_lon'].apply(convert_lat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory data analysis\n",
    "Data visualization is the graphic representation of data. It involves producing images that communicate relationships among the represented data to viewers of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['start_type','icon']\n",
    "for feature in cols:\n",
    "    features[feature].hist(bins=25)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(features.corr(), annot = True,fmt='.1g', vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2 , ax3) = plt.subplots(nrows=3, ncols=1, figsize=(20,20))\n",
    "\n",
    "\n",
    "sns.scatterplot(x=\"duration\",y=\"time\",data=features,ax=ax1)\n",
    "sns.scatterplot(x=\"cost_duration\",y=\"time\",data=features,ax=ax2)\n",
    "sns.scatterplot(x=\"price_duration\",y=\"time\",data=features,ax=ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling outliers\n",
    "features.drop(features[ (features['time']>200) & (features['duration']<400) ].index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2 , ax3) = plt.subplots(nrows=3, ncols=1, figsize=(20,20))\n",
    "\n",
    "\n",
    "sns.scatterplot(x=\"duration\",y=\"time\",data=features,ax=ax1)\n",
    "sns.scatterplot(x=\"cost_duration\",y=\"time\",data=features,ax=ax2)\n",
    "sns.scatterplot(x=\"price_duration\",y=\"time\",data=features,ax=ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets we visualize total riders for each day of week\n",
    "features_weekdays = features.pivot_table(index=['DayOfWeekNum','DayOfWeek'],\n",
    "                                  values='time',\n",
    "                                  aggfunc='count')\n",
    "features_weekdays.plot(kind='bar', figsize=(15,6))\n",
    "plt.ylabel('Total riders')\n",
    "#plt.set_xticklabels(x_labels)\n",
    "plt.title('Riders by Week Day');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_monthdays = features.pivot_table(index=['Month'],\n",
    "                                  values='time',\n",
    "                                  aggfunc='count')\n",
    "uber_monthdays.plot(kind='bar', figsize=(15,6))\n",
    "plt.ylabel('Total Riders')\n",
    "plt.title('Riders by Month Day');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the data by Weekday and hour\n",
    "summary = features.groupby(['DayOfWeek', 'Hour'])['time'].count()\n",
    "#convert to dataframe\n",
    "summary = pd.DataFrame(summary)\n",
    "#reset index\n",
    "summary = summary.reset_index()\n",
    "#rename last column\n",
    "summary=summary.rename(columns = {'time':'Counts'})\n",
    "#browse data\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_color_blind = [(0, 107, 164), (255, 128, 14), (171, 171, 171), (89, 89, 89),\n",
    "             (95, 158, 209), (200, 82, 0), (137, 137, 137), (163, 200, 236),\n",
    "             (255, 188, 121), (207, 207, 207)]\n",
    "\n",
    "for i in range(len(tableau_color_blind)):  \n",
    "    r, g, b = tableau_color_blind[i]  \n",
    "    tableau_color_blind[i] = (r / 255., g / 255., b / 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "\n",
    "## set palette   \n",
    "current_palette = sns.color_palette(tableau_color_blind)\n",
    "plt.figure(figsize=(15,6))\n",
    "ax = sns.pointplot(x=\"Hour\", y=\"Counts\", hue=\"DayOfWeek\", data=summary, palette = current_palette,)\n",
    "handles,labels = ax.get_legend_handles_labels()\n",
    "#reordering legend content\n",
    "handles = [handles[1], handles[5], handles[6], handles[4], handles[0], handles[2], handles[3]]\n",
    "labels = [labels[1], labels[5], labels[6], labels[4], labels[0], labels[2], labels[3]]\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "ax.set_xlabel('Hour', fontsize = 12)\n",
    "ax.set_ylabel('Count of Uber Pickups', fontsize = 12)\n",
    "ax.set_title('Hourly Uber Pickups By Day of the Week in Peru (Jan-X 2010)', fontsize=16)\n",
    "ax.tick_params(labelsize = 8)\n",
    "ax.legend(handles,labels,loc=0, title=\"Legend\", prop={'size':8})\n",
    "ax.get_legend().get_title().set_fontsize('8')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that peak hour is 1pm, very far as normal peak hour between 7am and 10am, and we see other peak after 9pm.\n",
    "\n",
    "It's very strange if time variable is relative to Lima (Perú), maybe it very similar with difference timezone, like as Europe timezone, so it make sense. The time difference is 6 or 7 hours Spain and Peru, ( winter or summer time). So I want to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(x=\"duration\", y=\"time\", col=\"start_type\", data=features)\n",
    "g = sns.lmplot(x=\"cost_duration\", y=\"time\", col=\"start_type\", data=features)\n",
    "g = sns.lmplot(x=\"price_duration\", y=\"time\", col=\"start_type\", data=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode data\n",
    "One-hot encoding is one of the most common encoding methods in machine learning. This method spreads the values in a column to multiple flag columns and assigns 0 or 1 to them. These binary values express the relationship between grouped and encoded column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode data\n",
    "def oneHotEncode(df, col):\n",
    "    dfDummies = pd.get_dummies(df[col], prefix = col)\n",
    "    df = pd.concat([df, dfDummies], axis=1)\n",
    "    \n",
    "    # write youe code here\n",
    "    df= df.drop([col], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the function to our data\n",
    "features = oneHotEncode(features, 'start_type')\n",
    "#features = oneHotEncode(features, 'DayOfWeekNum')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "In most cases, the numerical features of the dataset do not have a certain range and they differ from each other. In real life, it is nonsense to expect age and income columns to have the same range. But from the machine learning point of view, how these two columns can be compared?  \n",
    "<b> Scaling </b> solves this problem. The continuous features become identical in terms of the range, after a scaling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "def scale(df, cols):     \n",
    "    for col in cols:\n",
    "        \n",
    "        # write your code here: \n",
    "        df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    return df\n",
    "features = scale(features, [\"cost_duration\",\"price_duration\",\"distance\",\"duration\",\"start_lat\",\"start_lon\",\"end_lat\",\"end_lon\"]) \n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model fitting and predicting using SVR and XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from math import sqrt\n",
    "from sklearn.metrics import make_scorer, accuracy_score \n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "labels=features[\"time\"]\n",
    "features.drop([\"time\",\"icon\",\"end_state\",\"source\",\"Month\",\"DayOfWeek\",\"DayOfWeekNum\",\"Day\",\"Hour\"], axis=1, inplace = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop([\"DayOfWeek\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "score_lr = r2_score(y_test, pred)\n",
    "rmse_lr = sqrt(mean_squared_error(y_test, pred))\n",
    "print('Coefficient of determination: %.2f' % score_lr)\n",
    "print('Mean squared error: %.2f' % rmse_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "score_gnb = r2_score(y_test, pred)\n",
    "rmse_gnb = sqrt(mean_squared_error(y_test, pred))\n",
    "print('Coefficient of determination: %.2f' % score_gnb)\n",
    "print('Mean squared error: %.2f' % rmse_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf  = RandomForestRegressor(max_depth=10, random_state=42, n_estimators=100, min_samples_split = 150)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "score_rfr = r2_score(y_test, pred)\n",
    "rmse_rfr = sqrt(mean_squared_error(y_test, pred))\n",
    "print('Coefficient of determination: %.2f' % score_rfr)\n",
    "print('Mean squared error: %.2f' % rmse_rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDRegressor()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "score_sgd = r2_score(y_test, pred)\n",
    "rmse_sgd = sqrt(mean_squared_error(y_test, pred))\n",
    "print('Coefficient of determination: %.2f' % score_sgd)\n",
    "print('Mean squared error: %.2f' % rmse_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) SVR Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# First, let's choose which kernel is the best for our data\n",
    "\n",
    "for k in ['linear','poly','rbf','sigmoid']:\n",
    "    clf = svm.SVR(kernel=k)\n",
    "    clf.fit(X_train, y_train)\n",
    "    confidence = clf.score(X_train, y_train)\n",
    "    print(k,confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "clf = svm.SVR(kernel ='poly')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "score_svr = r2_score(y_test, pred)\n",
    "rmse_svr = sqrt(mean_squared_error(y_test, pred))\n",
    "print('Coefficient of determination: %.2f' % score_svr)\n",
    "print('Mean squared error: %.2f' % rmse_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot prediction and actual data\n",
    "plt.plot(y_test, pred, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2) XGBoost regressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is well known to provide better solutions than other machine learning algorithms. In fact, since its inception, it has become the \"state-of-the-art” machine learning algorithm to deal with structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will convert the dataset into an optimized data structure called Dmatrix that XGBoost supports and gives it acclaimed performance and efficiency gains. You will use this later in the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Parameters with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the accuracy of our model by turning the hyperparameters of our Random Forest model. We will run a GridSearchCV to find the best parameters for the model and use that model to train and test our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost's hyperparameters\n",
    "At this point, before building the model, you should be aware of the tuning parameters that XGBoost provides. Well, there are a plethora of tuning parameters for tree-based learners in XGBoost and you can read all about them here. But the most common ones that you should know are:\n",
    "\n",
    "<b> learning_rate </b>: step size shrinkage used to prevent overfitting. Range is [0,1] \n",
    "\n",
    "<b> max_depth </b>: determines how deeply each tree is allowed to grow during any boosting round.\n",
    "\n",
    "<b> subsample </b>: percentage of samples used per tree. Low value can lead to underfitting.\n",
    "\n",
    "<b> colsample_bytree </b>: percentage of features used per tree. High value can lead to overfitting.\n",
    "\n",
    "<b> n_estimators </b>: number of trees you want to build.\n",
    "    \n",
    "objective: determines the loss function to be used like reg:linear for regression problems, reg:logistic for classification problems with only decision, binary:logistic for classification problems with probability.\n",
    "XGBoost also supports regularization parameters to penalize models as they become more complex and reduce them to simple (parsimonious) models.\n",
    "\n",
    "<b> gamma </b>: controls whether a given node will split based on the expected reduction in loss after the split. A higher value leads to fewer splits. Supported only for tree-based learners.\n",
    "\n",
    "<b> alpha </b>: L1 regularization on leaf weights. A large value leads to more regularization.\n",
    "\n",
    "<b> lambda </b>: L2 regularization on leaf weights and is smoother than L1 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various hyper-parameters to tune\n",
    "xgb1 = xgb.XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(X_train,y_train)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that we have the optimal parameters for our XGboost regressor, we can build a new model with those parameters to fit and use on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = xgb_grid.best_estimator_\n",
    "\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the rmse by invoking the mean_sqaured_error function from sklearn's metrics module.\n",
    "\n",
    "pred = rf_clf.predict(X_test)\n",
    "rmse_xgb = sqrt(mean_squared_error(y_test, pred))\n",
    "\n",
    "print(rmse_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_xgb=r2_score(y_test, pred)\n",
    "\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot prediction and actual data\n",
    "plt.plot(y_test, pred, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = pd.DataFrame({\n",
    "    \"Model\": [\"LinearRegression\", \"SVR\", \"GaussianNB\", \n",
    "              \"RandomForestRegressor\", \"SGDRegressor\", \"XGBoostRegressor\"],\n",
    "    \"Coefficient of determination\": [score_lr, score_svr,score_gnb, score_rfr, \n",
    "              score_sgd, score_xgb],\n",
    "    \"Root-mean-square error\": [rmse_lr, rmse_svr,rmse_gnb, rmse_rfr, \n",
    "              rmse_sgd, rmse_xgb]\n",
    "})\n",
    "\n",
    "model_performance.sort_values(by=\"Coefficient of determination\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
